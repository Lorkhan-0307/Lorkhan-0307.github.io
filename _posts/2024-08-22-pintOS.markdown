---
layout: post
title:  "PintOS 제작기 - 1"
date:   2024-08-22 12:00:00 +0900
categories: computer_structures
tags: [C, 운영체제]
use_math: true
---

# PintOS

# 서론

PintOS 중 우리는 카이스트에서 개발한 운영체제를 직접 만들어본다.
이는 주차들로 나뉘어 각각의 프로젝트를 만들게 된다.

## Project 1 - 서론

Project 1에서는 Base kernel의 Source Code를 제작하게 된다.
이는 threads directory에 있다.

또한, I/O device interfacing 과정을 진행하게 되는데, 이는 devices directory에 있다.

## Project 2 - 서론

Project 2 에서는 User Program Loader를 제작하게 된다.
이는 userprog directory에 있다.

lib directory에서 standard C library의 일부를 implement 하게 된다.

## Project 3 - 서론

Project 3 에서는 Virtual Memory를 구현하게 된다.
이는 vm directory에 있다.

## Project 4 - 서론

Project 4 에서는 basic file system을 구현하게 된다.
이는 filesys directory에 있다.

이는 사실 project 2에서 실제로 처음 사용하게 되지만, 내부를 수정하는 것은 Project 4에 와서 진행한다.


# 본론

# Project 1

Project 1에서는 먼저 최소한의 작동하는 쓰레드 시스템을 제공한다.
우리는 이를 확장시키어 동기 문제들에 대해 더 잘 이해하게 될 것이다.
우리는 기본적으로 `threads` directory에서 작업을 진행하고, 또한 `devices` directory에서도 일부의 작업을 진행할 필요성이 있다.
`threads` directory에서 이후 합치는 작업을 진행해야 하며, 이 아래를 진행하기 전에 [Synchronization](https://casys-kaist.github.io/pintos-kaist/appendix/synchronization.html)을 한번 읽어보는 것이 좋겠다.

## Backgrounds

### Understanding Threads

먼저, initial thread system의 코드를 읽고 이해해라.
Pintos는 이미 쓰레드 생성, 쓰레드 Completion(완성, 종료), 쓰레드 사이의 Context Switching을 진행시키는 간단한 스케쥴러와 동기화의 가장 작은 요소들(세마포어, 락, 환경 변수, 최적화 배리어 등...)을 구현시켜 두었다.

코드가 처음에는 좀 어려울 수 있다. 아직 컴파일을 진행하고 베이스 시스템을 돌리지 않았다면, [Introduction](https://casys-kaist.github.io/pintos-kaist/)에서 다시 확인하여 진행하고 이곳으로 돌아오도록 해라.
소스 코드의 모든 부분을 편하게 확인할 수 있다. 필요하다면, `printf()` 문을 이곳저곳에 추가하고 이를 컴파일하여 돌려봄으로써 어떤 일들이 **어떤 순서로** 일어나는지 확인하도록 해라. 또한, 커널을 디버거에서 돌려서, 이곳저곳 흥미로운 지점들에 중단점(breakpoints)을 추가하여 코드 안쪽까지 데이터를 확인해보며 진행하여도 좋다.

쓰레드가 만들어질 때, 우리는 스케쥴될 새로운 context를 만든다. 우리는 이 상황에서 작동하는 함수를 만들어야 하며, 이는 `thread_create()`함수의 인자의 내용으로 전달될 것이다. 
처음 쓰레드가 스케쥴되고 동작할 때, 이 함수로 시작되며 이 내용이 실행될 것이다.
함수가 반환되면, 쓰레드가 종료된다. 각 쓰레드는, 그러므로, 미니 프로그램처럼 동작하며, 이는 `thread_create()`가 `main()` 처럼 실행되며 이에게 넘겨준다.

어떠한 아무런 시간이 주어진다면, 단 하나의 쓰레드만 동작해야 하며, 나머지가 있다면 이들은 비활성화된다.
스케쥴러는 다음에 어떤 쓰레드가 동작해야 하는지를 결정한다(만약 어떠한 쓰레드도 동작할 준비가 주어진 시간에 되지 않는다면, `idle()`로 구현된 특별한 *idle* 쓰레드가 동작한다.).

동기화의 가장 작은 단위들(Synchronization primitives)(위에 설명한 세마포어나 락, 환경변수 등)은 context switch를 한 쓰레드가 다른 쓰레드가 작업할 동안 기다려야 한다면 강제로 발생시킬수 있다.

Context Switch의 동작 과정은 `threads/thread.c` 안에 존재하는 `thread_launch()` 함수에 자세히 담겨 있다(꼭 이해할 필요는 없다.). 이는 현재 동작중인 쓰레드의 상태를 저장하고, 우리가 동작시키고자 하는 쓰레드의 상태를 복원한다.

GDB 디버거를 통해, 천천히 Context Switch를 따라가보면([GDB 문서](https://casys-kaist.github.io/pintos-kaist/project1/introduction.html)) 어떤 일이 일어나는지 알 수 있다.
`schedule()` 함수에 breakpoint를 넣어서 시작해보고, single-step을 넘어가며 확인해봐라.
지속적으로 쓰레드의 주소와 상태를 확인해야 함을 꼭 기억하고, 각 쓰레드별로 어떤 작업들이 call stack에 있는지 확인해라. `do_iret()`에 있는 `iret`이 실행될 때, 다른 쓰레드가 돌아가기 시작한다는걸 곧 알 수 있을 것이다.

**주의사항**: Pintos에서, 각 쓰레드는 4 kB이하의 작은 고정된 실행 스택으로 규정되어 있다. 커널은 스택 오버플로우를 탐지하려 하지만, 이를 완벽하게 해내지는 못한다. 동적 지역변수로 거대한 데이터 구조를 선언하게 되면(예시 : `int buf[1000];`) 전혀 원인파악이 되지않는 커널 패닉(Kernel Panic)등의 기묘한 문제들을 여러분은 일으킬 수 있다. 

이러한 스택 할당의 대안으로는 페이지 할당기와 블록 할당기 등이 존재한다([Memory Allocation 참고](https://casys-kaist.github.io/pintos-kaist/appendix/memory_allocation.html)).

### Source Files

`threads` 와 `include/threads` 의 대한 간략한 요약이다.
이의 대부분의 코드는 굳이 수정할 필요가 없으나, 이를 보면 조금이나마 과제를 수월하게 해낼 수 있을 것이다.

이것들은 [여기](https://casys-kaist.github.io/pintos-kaist/project1/introduction.html)참고합시다.

### Development Suggestions

과거 많은 그룹들은 업무를 분할하였으며, 각 그룹 인원들은 자신의 분담된 업무를 데드라인 직전즈음까지 작업하였다. 이후, 그룹은 이들을 Merge하여 완성된 파일을 만들었는데, 이는 **매우** 좋지 않은 생각이다. 부디 이런방식으로 진행하지 않기를 바란다.
서로간의 코드를 합치다 발생한 오류를 해결하기 위해 마지막 시간들을 부디 허비하지 마라.

대신, git 등을 이용해 소스 코드 컨트롤을 미리미리 진행하여라. 

다양한 버그에 마주칠 수 잇는데, 이럴 때 다시 디버깅 도구들의 appendix를 읽고 해결하여라.
backtraces를 확인하며 kernel panic이나 assertion failure를 해결하기를 바란다.

## Alarm Clock

**devices/timer.c`에 있는 `timer_sleep()`을 다시 구현해**

물론 이미 작동되는 구현이  되어있지만, 이는 **busy wait** 방식을 사용한다.
busy wait은 계속 `thread_yield()` 함수를 통해 현재 시간을 확인하는 루프 속에 계속 존재하여, 충분한 시간이 지날때까지를 기다리는 방식이다.
이를 피할 수 있는 방식을 재구현해라.

---

```c
void timer_sleep (int64_t ticks);
```
쓰레드를 부르는 작업을 시간이 최소 x timer ticks 만큼 지나기 전까지 멈춘다.
만약 시스템이 idle 상태가 아니라면, 쓰레드가 정확히 x tick 직후 깨어나는 것이 아니고, 적절한 시간 이후에 아무런 ready queue를 선택하게 된다.

`timer_sleep()`은 분명 real-time(실시간)으로 동작하는(예시로 커서를 1초에 한번 깜빡이는 동작) 쓰레드에는 도움이 되는 방식이다.
`timer_sleep()`은 인자가 timer tick 의 형태로 구현되어 있으며, milliesecond나 다른 unit으로 구현되어 있지 않다.
`TIMER_FREQ` timer tick per second가 구현이 되어있는데, 이는 `devices/timer.h`에서 확인 가능하며, 기본 값은 `100`이다.
어지간하면 이는 변환하지 않도록 해라.

`timer_msleep()`, `timer_usleep()`, 그리고 `timer_nsleep()`과 같은 다른 함수들은 milliseconds, microseconds, nanoseconds 등을 위해 존재한다.
하지만, 이들 역시 필요에 따라 `timer_sleep()`을 호출할 것이기에, 이를 수정할 필요는 없다.
추후에 이를 자주 사용하지는 않을 수 있으나, 프로젝트 4 에서 유용하게 사용될 수 있다.

## Priority Scheduling(우선순위 스케쥴링)

**Pintos에서 Priority Scheduling과 Priority Donation을 구현하라**

ready list에 추가된 쓰레드가 현재 작동중인 쓰레드보다 더 높은 우선순위를 가지고 있을 때, 현재 작동중인 쓰레드는 즉시 프로세서를 새로운 쓰레드에 양보해야 한다.
유사하게, 쓰레드가 락, 세마포어나 환경 변수 등을 기다리고 있을 때, 가장 높은 우선 순위를 가지고 있는 대기중인 쓰레드가 가장 먼저 깨어나야 한다. 쓰레드는 우선순위가 시간의 경과에 따라 높아지거나 낮아질 수 있으나, 쓰레드의 우선순위가 낮아질 때, 자신이 가장 높은 우선순위 쓰레드가 아닌 경우 즉각적으로 CPU의 점유를 놓아야 할 것이다.

쓰레드 우선순위는 `PRI_MIN(0)` 부터 `PRI_MAX(63)` 까지 존재한다. 낮은 번호는 낮은 우선순위와 동일한 의미이며, 이로 인해 우선순위 0은 우선순위 중 가장 낮고, 우선순위 63은 우선순위 중 가장 높다. 
쓰레드를 만들 때 우선순위는 `thread_create()` 함수의 인자로 받아진다. 만약 다른 우선순위를 결정할 이유가 없다면, `PRI_DEFAULT(31)`로 결정된다. `PRI_` 매크로들은 `threads/thread.h`에 존재하며, 이는 절대 수정하지 않도록 한다.

우선순위 스케쥴링에서 발생할 수 있는 문제 중 하나는 "Priority Inversion(우선순위 반전)"이다.
상, 중, 하의 우선순위를 가지고 있는 세 개의 쓰레드 *H*, *M*, *L*을 가정하자.
만약, *H*가 *L*을 기다려야 하고(예시로, *L*이 락을 가지고 있는 경우), *M*이 이미 ready list에 올라가 있다면, *H*는 낮은 우선순위를 지니고 있는 *L*이 CPU를 점유하고 쓰레드를 완료하여 락을 반환해야 하는데, 이를 진행하지 못하므로 영원히 CPU를 가질 수 없다.

---
조금 더 상세한 설명

위 상황을 잘 보면, 현재 우선순위가 가장 높은 *H*가 CPU를 점유하고 있는데, 역으로 *L*이 먼저 종료되어야지만 *H*를 진행할 수 있다. 그렇지만, ready list에도 이미 *M*이 존재하고, *L*을 ready list에 추가해도 *M*보다 우선순위가 밀리므로 영원히 모두 실행될 수 없는 상황이 유지된다.

---
그렇기에, 이를 해결하기 위해서는 *H*가 **"기부"**를 진행하여, *L*이 락을 유지하는 동안 자신의 우선순위를 *L*에게 전달하고, *L*이 락을 놓게 되면(그리고 *H*가 락을 얻게 되면) 다시 자신이 기부한 자신의 우선순위를 되찾아 오는 방식으로 해결할 수 있다.

위에서 설명한 Priority Donation(우선순위 기부)를 구현하라. 이를 위해서는 우선순위 기부가 필요한 각기 다른 상황들에 대한 대처가 필요할 것이다. 하나의 쓰레드에 여러 개의 기부가 이루어질 수 있으므로 반드시 복수개의 기부를 감당할 수 있도록 진행하여야 한다. 예시로, *H*가 *M*이 가지고 있는 락을 기다리고 있고, 또한 *M*이 *L*이 가지고 있는 락을 기다리고 있다면, *H*는 *M*과 *L* 모두에 *H*의 우선순위가 기부되어야 할 것이다. 만약 필요하다면, level 8과 같은 적당한 우선순위 기부의 한계 깊이를 지정해야 한다.

또한 락을 위한 우선순위 기부 역시 구현되어야 한다. 다른 Pintos의 동기 구조체를 위한 우선순위는 굳이 기부할 필요는 없지만, 모든 상황에 대응되는 우선순위 스케쥴링은 구현해야 한다.

마지막으로, 쓰레드가 자신의 우선순위를 확인하고 수정할 수 있는 다음 함수들을 구현해라. 이들의 원형은 `threads/thread.c`에 구현되어 있다.

```c
void thread_set_priority(int new_priority);
// 현재 쓰레드의 우선순위를 new_priority로 수정한다. 현재 쓰레드가 이로 인해 최우선 순위가 아니라면, CPU를 놓아준다.
```

```c
int thread_get_priority(void);
// 현재 쓰레드의 우선순위를 반환한다. 우선순위 기부가 있다면, 더 높은 우선순위(기부받은 우선순위)를 반환한다.
```

다른 interface 등을 통해 한 쓰레드가 다른 쓰레드를 직접 우선순위를 수정하게 할 필요는 없다.

우선순위 스케쥴러는 다른 프로젝트들에 사용되지 않는다.


## Advanced Scheduler

**[4.4 BSD Scheduler](https://casys-kaist.github.io/pintos-kaist/project1/advanced_scheduler.html#4.4BSD%20Scheduler)와 유사한 multilevel feedback 큐 스케쥴러를 현재 시스템에서 진행중인 작업들에 대한 평균 response time을 감소시키기 위해 구현해라**

우선순위 스케쥴러와 마찬가지로, advanced scheduler는 우선순위를 기반으로 쓰레드를 선택하고 작동한다. 하지만, Advanced scheduler는 우선순위 기부가 일어나지 않는다. 그러므로, 우리는 우선순위 스케쥴러를 먼저 작동시키고, 이에서 우선순위 기부를 제거한 다음 advanced scheduler를 구현하는 것을 추천한다.

우리는 Pintos startup time에 어떠한 스케쥴링 알고리즘 정책을 사용할 것인지를 선택할 수 있도록 하는 코드를 작성하여야 한다. default(기본)로, 우선순위 스케쥴러가 작동하여야 지만, 또한 4.4BSD 스케쥴러를 `-mlfqs` 커널 옵션을 통해 선택할 수 있어야 한다. 이 옵션을 사용하면 옵션들이 `main()`에 존재하는 `parse_options()`에서 파싱될 때, `threads/thread.h`에 존재하는 `thread_mlfqs`를 true로 바꾼다.

4.4BSD 스케쥴러가 활성화되면, 쓰레드들은 더이상 직접 자신의 우선순위를 컨트롤하지 않는다. `thread_create()`에 전달되던 우선순위 인자들은 무시될 것이며, `thread_set_priority()`나 `thread_get_priority()`로 향하는 요청들은 스케쥴러에서 결정된 쓰레드의 현재 우선순위만 반환하게 될 것이다.

Advanced Scheduler는 추후 프로젝트에서 사용하지 않는다.


### 4.4BSD Scheduler

일반적 사용을 위한 스케쥴러의 목표는 쓰레드들의 밸런스를 서로 다른 스케쥴링의 필요성에 맞추는 것이다.
많은 I/O를 필요로 하는 쓰레드는 지속적으로 input 및 output devices 들을 계속 바쁘게 하기 위해 빠른 response time을 필요로 하지만, CPU는 비교적 짧은 시간동안만을 필요로 한다. 반대의 경우로, 연산을 필요로 하는 쓰레드의 경우, 상대적으로 긴 시간의 CPU를 필요로 하지만, fast response time은 전혀 필요하지 않다. 이 둘 사이에 놓인 또 다른 쓰레드들은, I/O 에 의존적인 연산 시간을 가지고 있어, 그 사이의 시간들을 또 필요로 할 수도 있다. 훌륭하게 설계된 스케쥴러의 경우, 이러한 다수의 조건들을 동시에 쓰레드들에 제공할 수 있다.

프로젝트 1을 위해서, 우리는 이 appendix에 설명된 스케쥴러를 구현하여야 한다. 우리의 스케쥴러는 [McKusik]에 설명되어 있는 것과 유사하며, 이것은 하나의 multilevel feedback 큐 스케쥴러의 예시이다. 이 형태의 스케쥴러는 다수의 ready-to-run 쓰레드들이 들어있는 큐를 유지하며, 각 큐는 각기 다른 우선순위를 가지고 있는 쓰레드들을 가지고 있다. 아무 때나, 스케쥴러는 가장 높은 우선순위를 가지고 있는 비어있지 않은 큐로부터 쓰레드를 선택한다. 만약 가장 높은 우선순위 큐가 여러개의 쓰레드를 가지고 있는 경우, 이들을 **"Round Robin"** 방식으로 실행시킨다.

스케쥴러의 Multiple facets는 데이터가 특정 수의 timer tick이 지난 후, 업데이트 되기를 필요로 한다. 모든 경우, 이러한 업데이트들은 일반 커널 쓰레드가 작동 기회를 얻기 전에 일어나야만 하며, 이를 통해 커널 쓰레드가 `timer_ticks()`은 새로이 증가한 값을 받으나, 예전 스케쥴러의 데이터 값을 받는 상황이 없게 한다.

4.4BSD 스케쥴러는 우선순위 기부를 필요로 하지 않음을 다시 강조한다.


#### Niceness

쓰레드 우선순위는 스케쥴러로부터 아래에 제시된 공식을 기반으로 유동적으로 결정된다. 하지만, 각 쓰레드는 nice value라고 하는 정수를 가지고 있으며, 이는 얼마나 해당 쓰레드가 다른 쓰레드들에게 "nice" 한지를 나타낸다. 만약 nice가 0이면 이는 쓰레드 우선순위에 영향을 끼치지 않는다. nice가 양수인 경우(max는 20), 쓰레드의 우선순위를 감소시키고, 받을 수 있던 CPU 시간을 조금 감소시키게 한다. 반대로 음수인 경우(min은 -20), 다른 쓰레드들로부터 CPU 시간을 뺏어온다.

시작 쓰레드는 nice값이 0으로 시작된다. 다른 쓰레드들 중 nice value가 있는 경우, 이는 자신의 부모 쓰레드로부터 받아온다. 우리는 아래에 설명된 함수들을 구현해야 하며, 이들은 테스트 프로그램을 위해서 사용된다. 이들의 원형은 `threads/thread.c`에 존재한다.

```c
int thread_get_nice(void);
// 현재 쓰레드의 nice value를 반환한다.
```

```c
int thread_set_nice(int nice);
// 현재 쓰레드의 nice value를 새로운 nice value로 수정하고, 다시 쓰레드의 우선순위를 새로 결정된 nice value를 기반으로 계산한다(바로 아래의 Calculating Priority를 참고할 것). 만약 현재 작동중인 쓰레드가 가장 높은 우선순위가 아니라면, CPU의 점유를 포기한다.
```

### Calculating Priority

우리의 스케쥴러는 64개의 우선순위가 있으므로 64개의 ready 큐가 있어야 할것이며, 이들은 0`(PRI_MIN)` 부터 63`(PRI_MAX)`까지 번호가 메겨질 것이다. 작은 숫자들은 낮은 우선순위와 연결될 것이고ㅡ 그로 인해 우선순위 0이 가장 낮은 우선순위일 것이며, 우선순위 63이 가장 높은 우선순위를 가지고 있을 것이다. 쓰레드 우선순위는 쓰레드 생성시에 계산되며, 또한 모든 쓰레드에 대해 매 4회의 clock tick마다 재계산될 것이다. 어느 경우에서든, 아래의 계산식에 의해 결정된다.

$priority = PRI_MAX - (recent_cpu / 4) - (nice * 2)$

recent_cpu는 쓰레드가 최근에 사용한 cpu의 시간을 의미하고(이는 하단의 calculating recent_cpu 를 참고) nice 는 쓰레드의 nice value를 의미한다. 결과는 내림을 통해 가장 가까운 정수로 바꿔야 한다. recent_cpu와 nice에 곱해지는 $1/4$ 와 $2$ 는 최적화된 값으로 알고 있지만, 그보다 더 깊은 의미는 가지지 않는다. 계산된 우선순위는 반드시 가능 범위인 `PRI_MIN`과 `PRI_MAX` 사이에 존재하여야 하므로 조정되어야 한다.

이 공식은  최근 CPU time을 받았던 쓰레드가 다음에 스케쥴러가 작동할 때 CPU에게 재할당되지 않도록 하기 위해 낮은 우선순위를 부여한다. 이는 **기아 현상**을 감소시키는 매우 중요한 방법이다.
CPU 시간을 최근에 아예 받지 못한 쓰레드가 recent_cpu 값으로 0을 가지고 있게 되므로, 높은 nice value를 부여하여, 쓰레드가 반드시 CPU 시간을 곧 받게 하는 방식으로 작동한다.

### Calculating `recent_cpu`

현재 미작성

### Calculating `load_avg`

현재 미작성

### Summary

현재 미작성

### Fixed-Point Real Arithmetic

현재 미작성



